{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ASR (Automatic Speech Recognition) using wav2vec\n\nThis notebook uses pre-trained huber model from HuggingFace to convert Audio to transcript (added youtube download code snippet because it's convenient :)\n\n**However the biggest challenge is to improve the transcription quality** - \n\n    1. we've used silence removal for that\n    2. large audio chunks don't produce good transcription quality, so we've used sliding window \n    3. wanted to use/perform some audio filter/pre-processing (please suggest some, I have no idea which ones to use)","metadata":{}},{"cell_type":"code","source":"#!pip install -r requirements.txt\n!pip install librosa pydub torch transformers pytube","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWw5Ihj4Z6_4","outputId":"4f49c9e8-2def-4ff7-c687-55660c074e1b","execution":{"iopub.status.busy":"2023-03-05T12:46:01.356524Z","iopub.execute_input":"2023-03-05T12:46:01.358175Z","iopub.status.idle":"2023-03-05T12:46:37.071412Z","shell.execute_reply.started":"2023-03-05T12:46:01.358111Z","shell.execute_reply":"2023-03-05T12:46:37.070494Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.10.0)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (0.25.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.13.0+cpu)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\nCollecting pytube\n  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.56.4)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (4.4.0)\nRequirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.21.6)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.7.3)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.2.0)\nCollecting soundfile>=0.12.1\n  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.3.3)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.7/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.1)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.51.0->librosa) (59.8.0)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.51.0->librosa) (0.39.1)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nInstalling collected packages: pytube, soundfile\n  Attempting uninstall: soundfile\n    Found existing installation: soundfile 0.11.0\n    Uninstalling soundfile-0.11.0:\n      Successfully uninstalled soundfile-0.11.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nwfdb 4.1.0 requires SoundFile<0.12.0,>=0.10.0, but you have soundfile 0.12.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pytube-12.1.2 soundfile-0.12.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pytube import YouTube\nimport os,shutil\n\nimport audioread\nfrom IPython.display import Audio\nimport librosa\nfrom pydub import AudioSegment, silence\n\nimport torch\nfrom transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration, Wav2Vec2Processor, HubertForCTC\n","metadata":{"id":"cf5bYNifadLO","execution":{"iopub.status.busy":"2023-03-05T12:46:57.481071Z","iopub.execute_input":"2023-03-05T12:46:57.481490Z","iopub.status.idle":"2023-03-05T12:47:10.495599Z","shell.execute_reply.started":"2023-03-05T12:46:57.481446Z","shell.execute_reply":"2023-03-05T12:47:10.494359Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Load pre-trained Hubert model (used Connectionist Temporal Classification/CTC loss ) from HuggingFace\n## This particular model works for English, however threre are models that support other languages too\n\nmodel_name = \"facebook/hubert-large-ls960-ft\"\ntokenizer = Wav2Vec2Processor.from_pretrained(model_name)\nmodel = HubertForCTC.from_pretrained(model_name)","metadata":{"id":"I7HfybqQa_iP","execution":{"iopub.status.busy":"2023-03-05T13:11:29.431467Z","iopub.execute_input":"2023-03-05T13:11:29.431901Z","iopub.status.idle":"2023-03-05T13:11:33.595740Z","shell.execute_reply.started":"2023-03-05T13:11:29.431849Z","shell.execute_reply":"2023-03-05T13:11:33.593928Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def download_audio(url=None):\n    for file in os.listdir():\n        if file.endswith(\"mp4\"):\n            os.remove(file)\n    if url!=None:\n        yt=YouTube(url)\n        print(yt.title)\n        stream=list(yt.streams.filter(only_audio=True, file_extension='mp4'))\n        stream[0].download() # stream has all .mp4 audios\n    else:\n        print(\"Invalid url,can't download\")","metadata":{"id":"IN5KHY50aDay","execution":{"iopub.status.busy":"2023-03-05T13:01:29.907156Z","iopub.execute_input":"2023-03-05T13:01:29.907512Z","iopub.status.idle":"2023-03-05T13:01:29.914890Z","shell.execute_reply.started":"2023-03-05T13:01:29.907483Z","shell.execute_reply":"2023-03-05T13:01:29.913190Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"url=\"https://www.youtube.com/watch?v=MihlCysVWNs\"\n#url=\"https://www.youtube.com/watch?v=YVQzFCPkgt4&list=PLreVlKwe2Z0QIdDwvVoa_3QSMifIF1w1A&index=7\"\ndownload_audio(url)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fo_dVR6XaDgN","outputId":"7467651e-6d15-4af7-ad09-be8c17457fb4","execution":{"iopub.status.busy":"2023-03-05T13:00:36.378815Z","iopub.execute_input":"2023-03-05T13:00:36.379210Z","iopub.status.idle":"2023-03-05T13:01:25.299216Z","shell.execute_reply.started":"2023-03-05T13:00:36.379175Z","shell.execute_reply":"2023-03-05T13:01:25.298142Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Wake up to Reality - Madara Uchiha's words\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert_to_wav(input_filename):\n    for file in os.listdir():\n        if file.endswith(\"wav\"):\n            os.remove(file)\n    ext=input_filename[-3:]\n    output_filename=filename[:-3]+\"wav\"\n    if ext==\"mp3\":\n        sound = AudioSegment.from_mp3(input_filename)\n    else:\n        sound = AudioSegment.from_file(input_filename,format=ext)\n    sound = sound.set_frame_rate(16000)\n    sound.export(output_filename,format=\"wav\")\n    os.remove(input_filename)\n    return output_filename","metadata":{"id":"Fqu3VhehaDiT","execution":{"iopub.status.busy":"2023-03-05T13:03:00.435379Z","iopub.execute_input":"2023-03-05T13:03:00.435746Z","iopub.status.idle":"2023-03-05T13:03:00.443445Z","shell.execute_reply.started":"2023-03-05T13:03:00.435717Z","shell.execute_reply":"2023-03-05T13:03:00.442328Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"## we need audio in wav format + sample rate 16K Hz\nfilename=\"\"\nfor file in os.listdir():\n    if file.endswith(\"mp4\"):\n        filename=file\nprint(\"old filename \",filename)\nfilename = convert_to_wav(filename)\nprint(\"new filename \", filename)","metadata":{"id":"tNK5C0wcaDkc","execution":{"iopub.status.busy":"2023-03-05T13:04:01.700452Z","iopub.execute_input":"2023-03-05T13:04:01.700852Z","iopub.status.idle":"2023-03-05T13:04:02.136805Z","shell.execute_reply.started":"2023-03-05T13:04:01.700819Z","shell.execute_reply":"2023-03-05T13:04:02.135637Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"old filename  Wake up to Reality - Madara Uchihas words.mp4\nnew filename  Wake up to Reality - Madara Uchihas words.wav\n","output_type":"stream"}]},{"cell_type":"code","source":"## create temporary directory to store \ntmp_dir=\"audio_chunks\"\n\nshutil.rmtree(f\"{tmp_dir}/\",ignore_errors=True)\nos.makedirs(tmp_dir)\n","metadata":{"id":"04Eon-3GhY92","execution":{"iopub.status.busy":"2023-03-05T13:04:12.509813Z","iopub.execute_input":"2023-03-05T13:04:12.510267Z","iopub.status.idle":"2023-03-05T13:04:12.517650Z","shell.execute_reply.started":"2023-03-05T13:04:12.510222Z","shell.execute_reply":"2023-03-05T13:04:12.516295Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"audio = AudioSegment.from_file(filename)\ndBs=audio.dBFS # get decibels \nsilence_list=silence.detect_silence(audio,min_silence_len=750,silence_thresh=dBs-14)\nsilence_list","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWCwVYhOi3gO","outputId":"bd20bc74-c0b3-484a-927b-f16d95224152","execution":{"iopub.status.busy":"2023-03-05T13:05:43.308224Z","iopub.execute_input":"2023-03-05T13:05:43.308583Z","iopub.status.idle":"2023-03-05T13:05:46.553521Z","shell.execute_reply.started":"2023-03-05T13:05:43.308528Z","shell.execute_reply":"2023-03-05T13:05:46.552550Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[[0, 2812], [51695, 52943], [54775, 55690]]"},"metadata":{}}]},{"cell_type":"code","source":"# test = audio[54775:55690]\n# path = \"/content/test_3.wav\"\n# test.export(path) #Exports to a mp3 file in the current path.\n    \n# Audio(path, autoplay=False)","metadata":{"id":"-vLsoNIdlcF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## while breaking into chunks we need to take care of following points\n\ndef create_chunk(audio,silence_list,threshold=14,max_interval=20000):\n\n    audio_length = int(audio.duration_seconds)*1000 ## we need value in (ms) not (s)\n    non_silent_chunk=[]\n    if len(silence_list)>0:\n        ## for 1st chunk \n        if silence_list[0][0]!=0:\n            nss=0 # non-silence chunk start\n            nse=silence_list[0][0] # non-silence chunk end\n            non_silent_chunk.append([nss,nse])\n        for idx in range(1,len(silence_list)):\n            nss=silence_list[idx-1][1]  # end of previous silence-chunk\n            nse=silence_list[idx][0]  # start of current silence-chunk\n            non_silent_chunk.append([nss,nse])\n\n        # after last silence chunk \n        if silence_list[-1][1]!=audio_length:\n            nss=silence_list[-1][1]\n            nse=audio_length\n            non_silent_chunk.append([nss,nse])\n    else:\n        non_silent_chunk.append([0,audio_length])\n\n    print(\"non_silent_chunk : \",non_silent_chunk)\n    new_non_silent_chunk = [] # we break larger non-silence chunk to smaller sub-chunks\n    # using sliding window to get audio without silence\n    for idx in range(len(non_silent_chunk)):\n        start=non_silent_chunk[idx][0]\n        end=non_silent_chunk[idx][1]\n        interval = end-start\n        if interval>max_interval:\n            s=start\n            while interval>max_interval:\n                e=s+max_interval+threshold\n                interval=interval-max_interval\n                new_non_silent_chunk.append([s,e])\n                s=e-threshold\n                start=s \n            if interval<=max_interval:\n                end=start+interval\n                new_non_silent_chunk.append([start,end])\n        else:\n            new_non_silent_chunk.append([start,end])\n\n    return new_non_silent_chunk\n\n\n","metadata":{"id":"E_AP-hVUl_FX","execution":{"iopub.status.busy":"2023-03-05T13:10:13.004915Z","iopub.execute_input":"2023-03-05T13:10:13.005303Z","iopub.status.idle":"2023-03-05T13:10:13.028917Z","shell.execute_reply.started":"2023-03-05T13:10:13.005267Z","shell.execute_reply":"2023-03-05T13:10:13.027909Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# test = audio[75690:95704]\n# path = \"/content/test_4.wav\"\n# test.export(path) #Exports to a mp3 file in the current path.\n# Audio(path, autoplay=False)","metadata":{"id":"K9FL6Muq-h29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transcribe_audio(path,model,tokenizer,audio,start,end,overlap=15):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    try:\n        with torch.no_grad():\n            new_audio = audio[start:end] \n            new_audio.export(path)  \n            print(path)\n            input_audio,sr=librosa.load(path,sr=16000)\n            input_values = tokenizer(input_audio,return_tensors=\"pt\").to(device).input_values\n            logits = model.to(device)(input_values).logits\n            prediction = torch.argmax(logits, dim=-1)\n            transcription = tokenizer.batch_decode(prediction)[0].lower()\n            transcription_start=transcription[:overlap]\n            transcription_end=transcription[-overlap:]\n            return transcription,transcription_start,transcription_end\n    except audioread.NoBackendError:\n        print(\"start value of chunk > end value of chunk\")\n        exit()\n","metadata":{"id":"JhPBD74XaD1Y","execution":{"iopub.status.busy":"2023-03-05T13:10:26.846671Z","iopub.execute_input":"2023-03-05T13:10:26.848011Z","iopub.status.idle":"2023-03-05T13:10:26.856821Z","shell.execute_reply.started":"2023-03-05T13:10:26.847969Z","shell.execute_reply":"2023-03-05T13:10:26.855563Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# max_interval - if audio chunk size > max_interval we breake it into chunk\n# threshold - gap between 2 chunks ,it uses soft boundary during transition of chunks\nnew_non_silent_chunk = create_chunk(audio,silence_list,threshold=14,max_interval=20000)\nprint(\"new_non_silent_chunk\",new_non_silent_chunk)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AELyzIAcPhPC","outputId":"da9353d3-39b4-44ae-a9bc-261d350a17d6","execution":{"iopub.status.busy":"2023-03-05T13:10:47.583937Z","iopub.execute_input":"2023-03-05T13:10:47.584378Z","iopub.status.idle":"2023-03-05T13:10:47.590611Z","shell.execute_reply.started":"2023-03-05T13:10:47.584338Z","shell.execute_reply":"2023-03-05T13:10:47.589483Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"non_silent_chunk :  [[2812, 51695], [52943, 54775], [55690, 96000]]\nnew_non_silent_chunk [[2812, 22826], [22812, 42826], [42812, 51695], [52943, 54775], [55690, 75704], [75690, 95704], [95690, 96000]]\n","output_type":"stream"}]},{"cell_type":"code","source":"overlap=20 ## change this value according to need\noverlapping_transcription=[]\ntranscription= \"\"\nroot_path=\"audio_chunks\"\nfor idx in range(len(new_non_silent_chunk)):\n    start=new_non_silent_chunk[idx][0]\n    end=new_non_silent_chunk[idx][1]\n    path=f\"{root_path}/chunk_{idx}.wav\"\n    orginal_trans,trans_start,trans_end=transcribe_audio(path,model,tokenizer,audio,start,end,overlap)\n    transcription+=orginal_trans+\" \"\n    overlapping_transcription.append([trans_start,trans_end])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8ymS9KlCrbq","outputId":"df6a21a0-5300-4842-8b1d-bcc6f59616d4","execution":{"iopub.status.busy":"2023-03-05T13:11:51.505170Z","iopub.execute_input":"2023-03-05T13:11:51.505665Z","iopub.status.idle":"2023-03-05T13:13:16.112094Z","shell.execute_reply.started":"2023-03-05T13:11:51.505615Z","shell.execute_reply":"2023-03-05T13:13:16.110671Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"audio_chunks/chunk_0.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\nIt is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_1.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_2.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_3.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_4.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_5.wav\n","output_type":"stream"},{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"audio_chunks/chunk_6.wav\n","output_type":"stream"}]},{"cell_type":"code","source":"transcription","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"AZUSlIU6CreV","outputId":"7d468e91-34d5-449b-8493-221844db1b41","execution":{"iopub.status.busy":"2023-03-05T13:16:37.537693Z","iopub.execute_input":"2023-03-05T13:16:37.538733Z","iopub.status.idle":"2023-03-05T13:16:37.547016Z","shell.execute_reply.started":"2023-03-05T13:16:37.538696Z","shell.execute_reply":"2023-03-05T13:16:37.545779Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'wake up to reality nothing ever goes as planned in this accursed world the longer you live the more you will realize that the only things that truly exist in this reality are merely pain suffering and futility listen everywhere you look in this world wherever there is light there will always be shadowys to be found as well as long as there is a conceft of victors the vanquished will also exist the selfish intent of wanting to preserve peace initiates wars and hatred is born in order to protect love there mexases causal relations ships that cannot be separated i want to sever the fate of this world a world of only victors world of only peace a world of only love i will create such a world i am the ghostt of the uchiha laa a p oa paportrul this reality esia eliaa pa aapo p n epa  '"},"metadata":{}}]},{"cell_type":"code","source":"overlapping_transcription","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-44XLmCwB_w","outputId":"abe80132-53ff-4915-8e05-7ae51b5d2bda","execution":{"iopub.status.busy":"2023-03-05T13:16:42.297063Z","iopub.execute_input":"2023-03-05T13:16:42.297518Z","iopub.status.idle":"2023-03-05T13:16:42.305323Z","shell.execute_reply.started":"2023-03-05T13:16:42.297475Z","shell.execute_reply":"2023-03-05T13:16:42.303942Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[['wake up to reality n', 'ere you look in this'],\n ['world wherever there', 'o protect love there'],\n ['mexases causal relat', 'e fate of this world'],\n ['a world of only vict', 'orld of only victors'],\n ['world of only peace ', ' of the uchiha laa a'],\n ['p oa paportrul this ', 'liaa pa aapo p n epa'],\n ['', '']]"},"metadata":{}}]},{"cell_type":"code","source":"model_name=\"flexudy/t5-small-wav2vec2-grammar-fixer\"\nt5_tokenizer=T5Tokenizer.from_pretrained(model_name)\nt5_model=T5ForConditionalGeneration.from_pretrained(model_name)\n","metadata":{"id":"Yhj_uVyUlOnj","execution":{"iopub.status.busy":"2023-03-05T13:16:47.079851Z","iopub.execute_input":"2023-03-05T13:16:47.080252Z","iopub.status.idle":"2023-03-05T13:16:52.578887Z","shell.execute_reply.started":"2023-03-05T13:16:47.080217Z","shell.execute_reply":"2023-03-05T13:16:52.577613Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"538065ecaff84aea94732fc3460c402c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)al_tokens_map.json\";:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b989c946db3949e1a2efabdff8e9c0ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)enizer_config.json\";:   0%|          | 0.00/2.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a962dbc3f64186b6516196160134a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"config.json\";:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ca01ceec66452fb3de6f7dec391dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6fb6f587c224c31938db73ae2774af2"}},"metadata":{}}]},{"cell_type":"code","source":"def add_punctuation(t5_model,t5_tokenizer,transcription):\n    input_text=\"fix:{\"+transcription+\"}</s>\"\n    input_ids=t5_tokenizer.encode(input_text,return_tensors=\"pt\",max_length=10000,truncation=True,add_special_tokens=True)\n    outputs=t5_model.generate(input_ids=input_ids,max_length=256,num_beams=4,repetition_penalty=1.0,\n                              length_penalty=1.0,early_stopping=True)\n    transcription=t5_tokenizer.decode(outputs[0],skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    return transcription","metadata":{"id":"_PfUwfcolWk9","execution":{"iopub.status.busy":"2023-03-05T13:18:28.229009Z","iopub.execute_input":"2023-03-05T13:18:28.229419Z","iopub.status.idle":"2023-03-05T13:18:28.237563Z","shell.execute_reply.started":"2023-03-05T13:18:28.229383Z","shell.execute_reply":"2023-03-05T13:18:28.236285Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def split_text(transcription,max_size):\n    cut2=max_size # max length we want a sentence to be\n    split_text_list=[]\n    nearest_idx=0\n    length=len(transcription)\n    \n    if cut2==length:   #  add complete text\n        split_text_list.append(transcription)\n    else:\n        while cut2<=length:\n            cut1=nearest_idx\n            cut2=nearest_idx+max_size\n            # split by period(.)\n            dots_idxs=[idx for idx,char in enumerate(transcription[cut1:cut2]) if char == \".\"]\n            if len(dots_idxs):\n                nearest_idx=max(dots_idxs)+1+cut1\n            else:     # split by space('\\b') , same as above\n                spaces_idxs=[idx for idx,char in enumerate(transcription[cut1:cut2]) if char == \" \"]\n                if len(spaces_idxs):\n                    nearest_idx=max(spaces_idxs)+1+cut1\n                else:\n                    nearest_idx=cut2+cut1\n            split_text_list.append(transcription[cut1:nearest_idx])\n\n    return split_text_list\n","metadata":{"id":"AMthtUNaoYbF","execution":{"iopub.status.busy":"2023-03-05T13:18:30.590039Z","iopub.execute_input":"2023-03-05T13:18:30.590492Z","iopub.status.idle":"2023-03-05T13:18:30.600220Z","shell.execute_reply.started":"2023-03-05T13:18:30.590447Z","shell.execute_reply":"2023-03-05T13:18:30.599124Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tmp_transcription=transcription\nsplit_text_list=split_text(tmp_transcription+\" \",512)\npunctuated_text=\"\"\n#gf = Gramformer(models = 1, use_gpu=True) # 1=corrector, 2=detector\nfor split_text in split_text_list:\n    tmp_text=add_punctuation(t5_model,t5_tokenizer,split_text)\n    #corrected_sentence = gf.correct(tmp_text,max_candidates=1)\n    #punctuated_text+=str(corrected_sentence)\n    punctuated_text+=tmp_text","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maL1GtcHnxvY","outputId":"665672c9-a16c-46dd-cf24-7fe7e167c1be","execution":{"iopub.status.busy":"2023-03-05T13:18:45.910017Z","iopub.execute_input":"2023-03-05T13:18:45.910403Z","iopub.status.idle":"2023-03-05T13:18:53.589707Z","shell.execute_reply.started":"2023-03-05T13:18:45.910369Z","shell.execute_reply":"2023-03-05T13:18:53.588230Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:227: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated\"\n","output_type":"stream"}]},{"cell_type":"code","source":"punctuated_text","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2ix-vRjNpcd_","outputId":"9b115ae4-bf72-4211-abf0-7c2804a29e0e","execution":{"iopub.status.busy":"2023-03-05T13:18:53.591736Z","iopub.execute_input":"2023-03-05T13:18:53.592049Z","iopub.status.idle":"2023-03-05T13:18:53.599971Z","shell.execute_reply.started":"2023-03-05T13:18:53.592017Z","shell.execute_reply":"2023-03-05T13:18:53.598799Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'wake up to reality nothing ever goes as planned in this accursed world. The longer you live, the more you will realize that the only things that truly exist in this reality are: pain, suffering, and futility. Listen everywhere you look in this world. Where there is light, there will always be shadowys to be found. As long as there is a conceft ofvictors, the vanquished will also exist: the selfish intention of wanting peace initiates wars, and hatred is born in order to protect love there.Mexases causal relations ships that cannot be separated (i want to severe the fate of this world, a world of only victories, world of only peace, a world of only love, i will create such a world, i am the ghostt of theuchiha laa, a p oa paportrul, this reality, esiaelia pa aapo, p n epa).'"},"metadata":{}}]},{"cell_type":"code","source":"#","metadata":{"id":"BGlPYbd9GcQ_"},"execution_count":null,"outputs":[]}]}